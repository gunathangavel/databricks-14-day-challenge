{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26a36a41-4f71-4cb1-8160-f0dbb9864a15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Model Comparision and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e18643a-118d-4143-adcc-b7a77f7d888c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import libraries. pandas for sklearn models and for sparkML we load using sparkDataframe\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0992c80d-8786-462d-afc5-ef1de50d5422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "spark.sql(\"USE CATALOG ecom_catalog\")\n",
    "spark.sql(\"USE SCHEMA ecom_schema\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db338524-b5fb-4cbf-a5d0-6aeec69d4f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>views</th><th>carts</th></tr></thead><tbody><tr><td>11448.0</td><td>603.0</td></tr><tr><td>268449.0</td><td>35236.0</td></tr><tr><td>11136.0</td><td>744.0</td></tr><tr><td>36374.0</td><td>148.0</td></tr><tr><td>2178.0</td><td>31.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         11448.0,
         603.0
        ],
        [
         268449.0,
         35236.0
        ],
        [
         11136.0,
         744.0
        ],
        [
         36374.0,
         148.0
        ],
        [
         2178.0,
         31.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "views",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "carts",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data load\n",
    "\n",
    "df_gold = spark.table(\"gold_events\").toPandas()\n",
    "df_gold_clean = df_gold.dropna()\n",
    "\n",
    "# predict purchase based on views and carts\n",
    "X = df_gold_clean[['views', 'carts']]\n",
    "y = df_gold_clean['purchases']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype(float) # best practice: Convert integer columns to float\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cacf5340-32f2-4dd2-a7b8-9f543c4c05ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Use scikit-learn (sklearn) \n",
    "#### - Purpose: Train multiple models quickly and find the best one comparing them using MLflow.\n",
    "#### - Runs on a single machine, Works best with small to medium datasets (fits in RAM)\n",
    "#### - Great for: quick experiments , model comparison, classical ML (regression, trees, random forest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a9214a0-48b6-4001-b0a3-739a4adf9a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " linear_regression    | R2 Score: 0.9954\n decision_tree        | R2 Score: 0.9475\n random_forest        | R2 Score: 0.8967\n"
     ]
    }
   ],
   "source": [
    "# Train 3 models and compare the metrics and track the results. \n",
    "\n",
    "models = {\n",
    "    \"linear_regression\": LinearRegression(),\n",
    "    \"decision_tree\": DecisionTreeRegressor(max_depth=5),\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=f\"Model_{name}\"):\n",
    "        # Log Hyperparameters\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        \n",
    "        # model Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict & Evaluate\n",
    "        score = model.score(X_test, y_test)\n",
    "        \n",
    "        # Log Metrics & Model\n",
    "        mlflow.log_metric(\"r2_score\", score)\n",
    "        mlflow.log_metric(\"mse\", mean_squared_error(y_test, model.predict(X_test)))\n",
    "\n",
    "        # NEW: create signature + input example\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        input_example = X_train.iloc[:1]\n",
    "\n",
    "        # Log model with signature + example\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            \"model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "   \n",
    "        print(f\" {name:20} | R2 Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92349cd9-7dfd-45fc-baa4-848bb12efe96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Spark ML\n",
    "#### - Runs distributed across a cluster, designed for big data (big data and distributed processing.)\n",
    "#### - Uses DataFrames and Pipelines\n",
    "#### - Great for:  large-scale preprocessing, training models on large datasets, production pipelines in Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af1f9144-4bc0-47c4-a93e-b44817bb2fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Build spark ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38226d15-6180-4ef3-8608-c66cf9714653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Spark ML Pipeline...\nSpark Linear Regression R2: 0.9862\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>category_code</th><th>views</th><th>carts</th><th>purchases</th><th>prediction</th></tr></thead><tbody><tr><td>electronics.tablet</td><td>8332</td><td>544</td><td>301</td><td>360.26051138710926</td></tr><tr><td>computers.peripherals.keyboard</td><td>21615</td><td>1599</td><td>1006</td><td>1026.881325182106</td></tr><tr><td>computers.peripherals.monitor</td><td>34169</td><td>2882</td><td>1658</td><td>1839.056542204622</td></tr><tr><td>electronics.audio.subwoofer</td><td>87516</td><td>4456</td><td>4082</td><td>2819.752124268129</td></tr><tr><td>computers.components.cooler</td><td>7900</td><td>562</td><td>342</td><td>371.906485863043</td></tr><tr><td>computers.components.power_supply</td><td>7981</td><td>644</td><td>415</td><td>424.11308952450275</td></tr><tr><td>computers.components.cpu</td><td>23803</td><td>1044</td><td>441</td><td>672.4002950208244</td></tr><tr><td>computers.components.memory</td><td>17747</td><td>1414</td><td>887</td><td>910.6220207763669</td></tr><tr><td>electronics.video.tv</td><td>386516</td><td>56813</td><td>32496</td><td>36051.41542169521</td></tr><tr><td>electronics.audio.acoustic</td><td>23794</td><td>302</td><td>216</td><td>199.69483808677916</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "electronics.tablet",
         8332,
         544,
         301,
         360.26051138710926
        ],
        [
         "computers.peripherals.keyboard",
         21615,
         1599,
         1006,
         1026.881325182106
        ],
        [
         "computers.peripherals.monitor",
         34169,
         2882,
         1658,
         1839.056542204622
        ],
        [
         "electronics.audio.subwoofer",
         87516,
         4456,
         4082,
         2819.752124268129
        ],
        [
         "computers.components.cooler",
         7900,
         562,
         342,
         371.906485863043
        ],
        [
         "computers.components.power_supply",
         7981,
         644,
         415,
         424.11308952450275
        ],
        [
         "computers.components.cpu",
         23803,
         1044,
         441,
         672.4002950208244
        ],
        [
         "computers.components.memory",
         17747,
         1414,
         887,
         910.6220207763669
        ],
        [
         "electronics.video.tv",
         386516,
         56813,
         32496,
         36051.41542169521
        ],
        [
         "electronics.audio.acoustic",
         23794,
         302,
         216,
         199.69483808677916
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "category_code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "views",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "carts",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "purchases",
         "type": "\"long\""
        },
        {
         "metadata": "{\"ml_attr\": {}}",
         "name": "prediction",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression as SparkLR\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load Spark data\n",
    "spark_df = spark.table(\"gold_events\").na.drop()\n",
    "\n",
    "# Converts features into a single vector. Spark models require a single features column.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"views\", \"carts\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "# define the model\n",
    "lr_spark = SparkLR(featuresCol=\"features\", labelCol=\"purchases\", maxIter=10, regParam=0.3)\n",
    "\n",
    "#build pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr_spark])\n",
    "\n",
    "# Train / test split\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Fit pipeline\n",
    "print(\"Training Spark ML Pipeline...\")\n",
    "spark_model = pipeline.fit(train_df)\n",
    "\n",
    "# make predictions\n",
    "predictions = spark_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"purchases\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "r2_spark = evaluator.evaluate(predictions)\n",
    "print(f\"Spark Linear Regression R2: {r2_spark:.4f}\")\n",
    "\n",
    "display(predictions.select(\"category_code\",\"views\",\"carts\",\"purchases\",\"prediction\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b666e60-7a3e-4761-b027-b0886515e431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Pipelines: A Pipeline (Assembler -> Model) is safer than running steps separately because it guarantees the exact same feature  transformations are applied to both training data and test data preventing data‑skew and leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d547e15-f01f-4833-9300-e5c26f7f496b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### MLflow for scikit‑learn → logs model parameters and metrics, saves the trained model, and can register in the Model Registry\n",
    "#### MLflow for Spark ML → logs parameters and metrics, and saves the entire pipeline (VectorAssembler + model + transformations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day13_modelcomp_feature_eng",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}