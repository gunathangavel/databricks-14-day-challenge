{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aa9e213-563c-4089-a8da-cb97daabb9db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Performance Optimization\n",
    "- Explain Plans: Shows how Spark will execute the query before running code.\n",
    "- Partitioning: Organizing data into dir level folders so Spark can skip entire partitions (Coarse-grained skipping).\n",
    "- Z-Ordering: Organizing data inside the files, so Spark can skip unnecessary data blocks (Fine-grained skipping).\n",
    "- Caching: Keeps frequently accessed data in memory to speed up repeated queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a129d06e-053b-4406-aa32-a73a0c1dbf78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>ecom_schema</td><td>bronze_events</td><td>false</td></tr><tr><td>ecom_schema</td><td>gold_events</td><td>false</td></tr><tr><td>ecom_schema</td><td>gold_product_performance</td><td>false</td></tr><tr><td>ecom_schema</td><td>silver_events</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "ecom_schema",
         "bronze_events",
         false
        ],
        [
         "ecom_schema",
         "gold_events",
         false
        ],
        [
         "ecom_schema",
         "gold_product_performance",
         false
        ],
        [
         "ecom_schema",
         "silver_events",
         false
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "database",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "tableName",
            "nullable": false,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isTemporary",
            "nullable": false,
            "type": "boolean"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 5
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "use ecom_catalog.ecom_schema;\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d918ab83-2a58-449c-879e-3b3d4a4ce27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonGroupingAgg(keys=[category_code#13634, brand#13635], functions=[finalmerge_count(merge count#13659L) AS count(1)#13641L])\n         +- PhotonShuffleExchangeSource\n            +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#8667]\n               +- PhotonShuffleExchangeSink hashpartitioning(category_code#13634, brand#13635, 1024)\n                  +- PhotonGroupingAgg(keys=[category_code#13634, brand#13635], functions=[partial_count(1) AS count#13659L])\n                     +- PhotonProject [category_code#13634, brand#13635]\n                        +- PhotonScan parquet ecom_catalog.ecom_schema.silver_events[event_type#13631,category_code#13634,brand#13635] DataFilters: [isnotnull(event_type#13631), (event_type#13631 = purchase)], DictionaryFilters: [(event_type#13631 = purchase)], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[s3://dbstorage-prod-27rwr/uc/1563c012-b284-4c86-9688-8f8dbadfdda3..., OptionalDataFilters: [], PartitionFilters: [], ReadSchema: struct<event_type:string,category_code:string,brand:string>, RequiredDataFilters: [isnotnull(event_type#13631), (event_type#13631 = purchase)]\n\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n== Optimizer Statistics (table names per statistics state) ==\n  missing = \n  partial = \n  full    = silver_events\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select category_code,brand,count(*) from silver_events where event_type= 'purchase' group by category_code, brand\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10331985-f647-450a-87d4-e9cea628cab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying partitioning based on event type.\n",
    "# Partitioned table\n",
    "spark.sql(f\"USE CATALOG ecom_catalog\")\n",
    "spark.sql(f\"USE SCHEMA ecom_schema\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE silver_events_partioned\n",
    "  USING DELTA\n",
    "  PARTITIONED BY (event_date, event_type)\n",
    "  AS SELECT * FROM silver_events\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5ab20b-0d9e-4632-96df-c01017ddf7bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize\n",
    "spark.sql(\"OPTIMIZE silver_events_partioned ZORDER BY (category_code, brand)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e56324e4-4bfb-4d9f-9b52-5eb48d989579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonGroupingAgg(keys=[category_code#18314, brand#18315], functions=[finalmerge_count(merge count#18366L) AS count(1)#18321L])\n         +- PhotonShuffleExchangeSource\n            +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#10315]\n               +- PhotonShuffleExchangeSink hashpartitioning(category_code#18314, brand#18315, 1024)\n                  +- PhotonGroupingAgg(keys=[category_code#18314, brand#18315], functions=[partial_count(1) AS count#18366L])\n                     +- PhotonProject [category_code#18314, brand#18315]\n                        +- PhotonScan parquet ecom_catalog.ecom_schema.silver_events_partioned[category_code#18314,brand#18315,event_date#18319,event_type#18311] DataFilters: [], DictionaryFilters: [], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[s3://dbstorage-prod-27rwr/uc/1563c012-b284-4c86-9688-8f8dbadfdda3..., OptionalDataFilters: [], PartitionFilters: [isnotnull(event_type#18311), (event_type#18311 = purchase)], ReadSchema: struct<category_code:string,brand:string>, RequiredDataFilters: []\n\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n== Optimizer Statistics (table names per statistics state) ==\n  missing = \n  partial = \n  full    = silver_events_partioned\n\n"
     ]
    }
   ],
   "source": [
    "# check explain after optimize\n",
    "spark.sql(\"select category_code,brand,count(*) from silver_events_partioned where event_type= 'purchase' group by category_code,brand\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9782532-0772-4b08-a9a5-f1f30858b958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on original unoptimized table...\n   Rows: 4632\n   Time (Original): 1.0346s\n\nRunning benchmark on OPTIMIZED (partitioned + ZORDER) table...\n   Rows: 4632\n   Time (Optimized): 1.0031s\n\n\uD83D\uDCCA Benchmark Summary\n---------------------\nOriginal Runtime : 4632\nOptimized Runtime: 4632\nâœ” Faster performance expected due to:\n   - Partition pruning (event_type)\n   - File compaction (OPTIMIZE)\n   - Data skipping (ZORDER on category_code, brand)\n"
     ]
    }
   ],
   "source": [
    "# bechmarking\n",
    "# Scenario: Measure performance of the GROUP BY query before and after OPTIMIZE + ZORDER.\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "import time\n",
    "\n",
    "# original unoptimized query (Lazy)\n",
    "df_original = (\n",
    "    spark.table(\"silver_events\")\n",
    "         .filter(col(\"event_type\") == \"purchase\")\n",
    "         .groupBy(\"category_code\", \"brand\")\n",
    "         .count()\n",
    ")\n",
    "\n",
    "print(\"Running benchmark on original unoptimized table...\")\n",
    "\n",
    "start = time.time()\n",
    "original_count = df_original.count()\n",
    "print(f\"   Rows: {original_count}\")\n",
    "print(f\"   Time (Original): {time.time() - start:.4f}s\\n\")\n",
    "\n",
    "# Define the optimized query  (Lazy). This uses your partitioned (silver_events_partioned) + ZORDERed table:\n",
    "\n",
    "df_optimized = (\n",
    "    spark.table(\"silver_events_partioned\")\n",
    "         .filter(col(\"event_type\") == \"purchase\")\n",
    "         .groupBy(\"category_code\", \"brand\")\n",
    "         .count()\n",
    ")\n",
    "\n",
    "print(\"Running benchmark on OPTIMIZED (partitioned + ZORDER) table...\")\n",
    "\n",
    "start = time.time()\n",
    "optimized_count = df_optimized.count()\n",
    "print(f\"   Rows: {optimized_count}\")\n",
    "print(f\"   Time (Optimized): {time.time() - start:.4f}s\\n\")\n",
    "\n",
    "# benchmarkSummary\n",
    "print(\"\uD83D\uDCCA Benchmark Summary\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Original Runtime : {original_count}\")\n",
    "print(f\"Optimized Runtime: {optimized_count}\")\n",
    "print(\" Faster performance expected due to:\")\n",
    "print(\"   - Partition pruning (event_type)\")\n",
    "print(\"   - File compaction (OPTIMIZE)\")\n",
    "print(\"   - Data skipping (ZORDER on category_code, brand)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8d5be05-43db-4f05-aebd-27d9793eed79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Caching is not supported on serverless compute hencce skipped.\n",
    "\n",
    "#cached = spark.table(\"silver_events\").cache()\n",
    "#cached.count()  # Materialize"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7519558699884052,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day10_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}